{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4eaa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "from datetime import datetime\n",
    "\n",
    "# Set environment variable for Google Application Credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'tmp/ethereum-data-nero.json'\n",
    "\n",
    "optimize_print = \"{:>2} | {:^32} | {:^32}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40f9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_hash():\n",
    "    \"\"\"\n",
    "    Read the last hash from the configuration file.\n",
    "\n",
    "    Returns:\n",
    "        str: The last hash value.\n",
    "    \"\"\"\n",
    "    with open(\"tmp/last_upload.txt\", \"r\") as file:\n",
    "        last_hash = int(file.read().strip())\n",
    "    return last_hash\n",
    "\n",
    "def write_last_hash(hash_value):\n",
    "    \"\"\"\n",
    "    Write the last hash to the configuration file.\n",
    "\n",
    "    Args:\n",
    "        hash_value (str): The hash value to be written.\n",
    "    \"\"\"\n",
    "    with open(\"tmp/last_upload.txt\", \"w\") as file:\n",
    "        file.write(hash_value)\n",
    "\n",
    "def get_last_optimization():\n",
    "    \"\"\"\n",
    "    Read the timestamp of the last optimization from the configuration file.\n",
    "\n",
    "    Returns:\n",
    "        int: The timestamp of the last optimization.\n",
    "    \"\"\"\n",
    "    with open(\"tmp/last_optimization.txt\", \"r\") as file:\n",
    "        last_opt = int(file.read().strip())\n",
    "    return last_opt\n",
    "\n",
    "def write_last_optimization(timestamp):\n",
    "    \"\"\"\n",
    "    Write the timestamp of the last optimization to the configuration file.\n",
    "\n",
    "    Args:\n",
    "        timestamp (int): The timestamp of the last optimization.\n",
    "    \"\"\"\n",
    "    with open(\"tmp/last_optimization.txt\", \"w\") as file:\n",
    "        file.write(timestamp)\n",
    "\n",
    "def get_active_stakers():\n",
    "    \"\"\"\n",
    "    Determine the active stakers.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of active stakers' addresses.\n",
    "    \"\"\"\n",
    "    #print(\"|--- determining stakers...\")\n",
    "    try:\n",
    "        stakers = pd.read_csv(\"users/stakers.csv\")\n",
    "        withdrawers = pd.read_csv(\"users/withdrawers.csv\")\n",
    "        stakers = stakers.groupby(\"address\")[\"blockNumber\"].max().reset_index()\n",
    "        withdrawers = withdrawers.groupby(\"address\")[\"blockNumber\"].max().reset_index()\n",
    "        addresses_to_remove = []\n",
    "        for _, withdrawer in withdrawers.iterrows():\n",
    "            active_stakers = stakers[stakers[\"blockNumber\"] > withdrawer[\"blockNumber\"]]\n",
    "            if withdrawer[\"address\"] in active_stakers:\n",
    "                continue\n",
    "            addresses_to_remove.append(withdrawer[\"address\"])\n",
    "\n",
    "        stakers = stakers[~stakers[\"address\"].isin(addresses_to_remove)]\n",
    "        #print(colored(\"|--- finished determining stakers.\", \"green\"))\n",
    "        return set(stakers[\"address\"])\n",
    "    \n",
    "    except:\n",
    "        print(\"FAILED TO GET ACTIVE STAKERS\")\n",
    "        return set()\n",
    "\n",
    "def optimize_announcements(df):\n",
    "    \"\"\"\n",
    "    Optimize the announcements data frame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The announcements data frame to be optimized.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The optimized announcements data frame.\n",
    "    \"\"\"\n",
    "    knownStakers = get_active_stakers()\n",
    "    df[\"staker\"] = df[\"sender\"].apply(lambda x: 1 if x in knownStakers else 0)\n",
    "    df_c = df.groupby(\"sender\")[\"metadata\"].count().reset_index().rename(columns={\"metadata\": \"senderCount\"})\n",
    "    df = pd.merge(df, df_c, on=\"sender\", how=\"left\")\n",
    "    df = df.sort_values([\"staker\", \"senderCount\", \"blockNumber\"], ascending=[False, True, False])\n",
    "    df.drop([\"senderCount\", \"staker\"], axis=1, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(\"users/announcements.csv\", index=None)\n",
    "    return df\n",
    "\n",
    "def blob_upload(announcements):\n",
    "    \"\"\"\n",
    "    Upload the announcements to Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "        announcements (pd.DataFrame): The announcements data frame to be uploaded.\n",
    "    \"\"\"\n",
    "    #print(\"|- uploading announcements...\")\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(\"eip5564_data\")\n",
    "    blob = bucket.get_blob(\"announcements.csv\")\n",
    "    blob.upload_from_string(announcements.to_csv())\n",
    "    #print(colored(\"|- finished uploading announcements.\", \"green\"))\n",
    "\n",
    "def optimize_and_upload():\n",
    "    \"\"\"\n",
    "    Optimize the announcements data frame and upload it to Google Cloud Storage.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def now():\n",
    "        return datetime.now().strftime('%B-%d %H:%M:%S ')\n",
    "\n",
    "    #print(optimize_print.format(\"x\", now(), \"start optimizing\"))\n",
    "    #print(colored(\"----optimizer-start----\", \"green\"))\n",
    "    if int(time.time()) < get_last_optimization() + 12:\n",
    "        return\n",
    "    \n",
    "    #print(\"start processing announcements:\")\n",
    "    announcements = pd.read_csv(\"users/announcements.csv\")\n",
    "    if int(pd.util.hash_pandas_object(announcements).sum()) == get_last_hash():\n",
    "        print(colored(\"nothing to do.                    \", \"grey\"))        \n",
    "        return\n",
    "    \n",
    "    announcements = optimize_announcements(announcements)\n",
    "    blob_upload(announcements)\n",
    "    write_last_hash(str(pd.util.hash_pandas_object(announcements).sum()))\n",
    "    write_last_optimization(str(int(time.time())))\n",
    "    #print(optimize_print.format(\"x\", now(), \"finished optimizing\"))\n",
    "    #print(colored(\"finished processing announcements.\", \"green\"))\n",
    "    #print(colored(\"----optimizer--end-----\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f033855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED TO GET ACTIVE STAKERS\n",
      "--       tsAdded  schemeID                              stealthAddress  \\\n",
      "0  1682326575         1  0x9bc57e30ccfacb70d23827da684fc0cf03eacb1b   \n",
      "1  1682325964         1  0x6d5684ca25d9efa4cd69caf777f7390159149e50   \n",
      "2  1682320849         1  0x1d6501e690e50bf7772eba95606daa6ff88c7c00   \n",
      "3  1682318706         1  0xe23fba6c1aa5495c3e4927fa2ec7132af78f39f6   \n",
      "4  1682317633         1  0x8b7048707f453d811c9d43735deb704d246a8dd5   \n",
      "5  1682317500         1  0x5b4c354518420d4cbaf384a4ced0e8ba2a1af59f   \n",
      "\n",
      "                                     ephemeralPubKey metadata  blockNumber  \\\n",
      "0  0x022fef12c58f1f348523317d331a92784afc554e5b56...     0xf0      3351081   \n",
      "1  0x032fc0589e301b82c40287ca3b1ad90e10d435c74f0d...     0x2f      3351038   \n",
      "2  0x02855605378acd634ec5e1d216621ca75e96b4696aca...     0x94      3350646   \n",
      "3  0x02ddc2a8847cad7a8dd53f14961149e79a5b8e0bf0ed...     0x51      3350491   \n",
      "4  0x02b0df150f371f02ef9ec084aae702d55bfd1f658f67...     0xe2      3350412   \n",
      "5  0x021fde2edd151096c3180ad38cbe85efe58d7631d5fe...     0x24      3350404   \n",
      "\n",
      "                                       sender  \n",
      "0  0xbbedd6d1f7900ec00e00d402e099ed89a7d8001b  \n",
      "1  0xbbedd6d1f7900ec00e00d402e099ed89a7d8001b  \n",
      "2  0xbbedd6d1f7900ec00e00d402e099ed89a7d8001b  \n",
      "3  0xbbedd6d1f7900ec00e00d402e099ed89a7d8001b  \n",
      "4  0xbbedd6d1f7900ec00e00d402e099ed89a7d8001b  \n",
      "5  0xbbedd6d1f7900ec00e00d402e099ed89a7d8001b  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'upload_from_string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     optimize_and_upload()\n",
      "Cell \u001b[0;32mIn [5], line 127\u001b[0m, in \u001b[0;36moptimize_and_upload\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m announcements \u001b[38;5;241m=\u001b[39m optimize_announcements(announcements)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m, announcements)\n\u001b[0;32m--> 127\u001b[0m \u001b[43mblob_upload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannouncements\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m write_last_hash(\u001b[38;5;28mstr\u001b[39m(pd\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mhash_pandas_object(announcements)\u001b[38;5;241m.\u001b[39msum()))\n\u001b[1;32m    129\u001b[0m write_last_optimization(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime())))\n",
      "Cell \u001b[0;32mIn [5], line 102\u001b[0m, in \u001b[0;36mblob_upload\u001b[0;34m(announcements)\u001b[0m\n\u001b[1;32m    100\u001b[0m bucket \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_bucket(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meip5564_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m blob \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mget_blob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers/announcements.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m \u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_from_string\u001b[49m(announcements\u001b[38;5;241m.\u001b[39mto_csv())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'upload_from_string'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    optimize_and_upload()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mev",
   "language": "python",
   "name": "mev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
